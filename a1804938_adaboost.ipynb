{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  1      2      3       4       5        6        7       8   \\\n",
       "0    842302  M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001   \n",
       "1    842517  M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869   \n",
       "2  84300903  M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974   \n",
       "3  84348301  M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414   \n",
       "4  84358402  M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980   \n",
       "\n",
       "        9   ...     22     23      24      25      26      27      28      29  \\\n",
       "0  0.14710  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
       "1  0.07017  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "2  0.12790  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
       "3  0.10520  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
       "4  0.10430  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
       "\n",
       "       30       31  \n",
       "0  0.4601  0.11890  \n",
       "1  0.2750  0.08902  \n",
       "2  0.3613  0.08758  \n",
       "3  0.6638  0.17300  \n",
       "4  0.2364  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv ('wdbc_data.csv', header = None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping ID column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([0, 1], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output values updated with 1 for B -> Benign and -1 for M -> Malignant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[1] = df[1].replace(['M','B'],[-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[1]\n",
    "y = y.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30) (569,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        2      3       4       5        6        7        8        9       10  \\\n",
       "0    17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010  0.14710  0.2419   \n",
       "1    20.57  17.77  132.90  1326.0  0.08474  0.07864  0.08690  0.07017  0.1812   \n",
       "2    19.69  21.25  130.00  1203.0  0.10960  0.15990  0.19740  0.12790  0.2069   \n",
       "3    11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140  0.10520  0.2597   \n",
       "4    20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800  0.10430  0.1809   \n",
       "..     ...    ...     ...     ...      ...      ...      ...      ...     ...   \n",
       "564  21.56  22.39  142.00  1479.0  0.11100  0.11590  0.24390  0.13890  0.1726   \n",
       "565  20.13  28.25  131.20  1261.0  0.09780  0.10340  0.14400  0.09791  0.1752   \n",
       "566  16.60  28.08  108.30   858.1  0.08455  0.10230  0.09251  0.05302  0.1590   \n",
       "567  20.60  29.33  140.10  1265.0  0.11780  0.27700  0.35140  0.15200  0.2397   \n",
       "568   7.76  24.54   47.92   181.0  0.05263  0.04362  0.00000  0.00000  0.1587   \n",
       "\n",
       "          11  ...      22     23      24      25       26       27      28  \\\n",
       "0    0.07871  ...  25.380  17.33  184.60  2019.0  0.16220  0.66560  0.7119   \n",
       "1    0.05667  ...  24.990  23.41  158.80  1956.0  0.12380  0.18660  0.2416   \n",
       "2    0.05999  ...  23.570  25.53  152.50  1709.0  0.14440  0.42450  0.4504   \n",
       "3    0.09744  ...  14.910  26.50   98.87   567.7  0.20980  0.86630  0.6869   \n",
       "4    0.05883  ...  22.540  16.67  152.20  1575.0  0.13740  0.20500  0.4000   \n",
       "..       ...  ...     ...    ...     ...     ...      ...      ...     ...   \n",
       "564  0.05623  ...  25.450  26.40  166.10  2027.0  0.14100  0.21130  0.4107   \n",
       "565  0.05533  ...  23.690  38.25  155.00  1731.0  0.11660  0.19220  0.3215   \n",
       "566  0.05648  ...  18.980  34.12  126.70  1124.0  0.11390  0.30940  0.3403   \n",
       "567  0.07016  ...  25.740  39.42  184.60  1821.0  0.16500  0.86810  0.9387   \n",
       "568  0.05884  ...   9.456  30.37   59.16   268.6  0.08996  0.06444  0.0000   \n",
       "\n",
       "         29      30       31  \n",
       "0    0.2654  0.4601  0.11890  \n",
       "1    0.1860  0.2750  0.08902  \n",
       "2    0.2430  0.3613  0.08758  \n",
       "3    0.2575  0.6638  0.17300  \n",
       "4    0.1625  0.2364  0.07678  \n",
       "..      ...     ...      ...  \n",
       "564  0.2216  0.2060  0.07115  \n",
       "565  0.1628  0.2572  0.06637  \n",
       "566  0.1418  0.2218  0.07820  \n",
       "567  0.2650  0.4087  0.12400  \n",
       "568  0.0000  0.2871  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     -1\n",
       "1     -1\n",
       "2     -1\n",
       "3     -1\n",
       "4     -1\n",
       "      ..\n",
       "564   -1\n",
       "565   -1\n",
       "566   -1\n",
       "567   -1\n",
       "568    1\n",
       "Name: 1, Length: 569, dtype: int32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = X.iloc[:300, :]\n",
    "\n",
    "X_test = X.iloc[301:, :]\n",
    "\n",
    "Y_train = y.iloc[:300, ]\n",
    "\n",
    "y_test = y.iloc[301:, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training function for custom adaboost classifier implementing sklearn decision stump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_adaboost_custom(X_Value, Y_Value, i , lr):\n",
    "    #empty arrays to store models and alphas\n",
    "    models = []\n",
    "    alphas = []\n",
    "    rows, columns = X_Value.shape\n",
    "    \n",
    "    #initialising weights with 1's\n",
    "    wt = np.ones(rows) / rows\n",
    "    \n",
    "    #training the model in for loop for specified number of iterations\n",
    "    for _ in range(i):\n",
    "        \n",
    "        #calling sklearn decision stump\n",
    "        dt_model = DecisionTreeClassifier(max_depth=1)\n",
    "        \n",
    "        dt_model.fit(X_Value, Y_Value, sample_weight = wt)\n",
    "        \n",
    "        #predicting the model values\n",
    "        predictions = dt_model.predict(X_Value)\n",
    "        \n",
    "        #calculating error\n",
    "        incorrect = (predictions != Y_Value)\n",
    "        err = ((incorrect*wt).sum())\n",
    "        \n",
    "        #adding small value to avoid division by 0\n",
    "        epsilon = 1e-10\n",
    "        \n",
    "        #Calculate alpha\n",
    "        a = lr * np.log((1.0 - err + epsilon) / (err + epsilon))\n",
    "        \n",
    "        #updating weight\n",
    "        wt = wt * np.exp(- a * Y_Value * predictions)\n",
    "        wt = wt / wt.sum()\n",
    "        \n",
    "        models.append(dt_model)\n",
    "        alphas.append(a)    \n",
    "    \n",
    "    return models,alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy for iterations 5 and learning rate 0.1 : 0.9366666666666666\n",
      "Training Accuracy for iterations 5 and learning rate 0.5 : 0.9566666666666667\n",
      "Training Accuracy for iterations 5 and learning rate 1 : 0.93\n",
      "Training Accuracy for iterations 5 and learning rate 1.5 : 0.9166666666666666\n",
      "Training Accuracy for iterations 5 and learning rate 2 : 0.9266666666666666\n",
      "Training Accuracy for iterations 25 and learning rate 0.1 : 0.9733333333333334\n",
      "Training Accuracy for iterations 25 and learning rate 0.5 : 1.0\n",
      "Training Accuracy for iterations 25 and learning rate 1 : 0.99\n",
      "Training Accuracy for iterations 25 and learning rate 1.5 : 0.94\n",
      "Training Accuracy for iterations 25 and learning rate 2 : 0.94\n",
      "Training Accuracy for iterations 50 and learning rate 0.1 : 0.98\n",
      "Training Accuracy for iterations 50 and learning rate 0.5 : 1.0\n",
      "Training Accuracy for iterations 50 and learning rate 1 : 0.9933333333333333\n",
      "Training Accuracy for iterations 50 and learning rate 1.5 : 0.12333333333333334\n",
      "Training Accuracy for iterations 50 and learning rate 2 : 0.11\n",
      "Training Accuracy for iterations 75 and learning rate 0.1 : 0.9866666666666667\n",
      "Training Accuracy for iterations 75 and learning rate 0.5 : 1.0\n",
      "Training Accuracy for iterations 75 and learning rate 1 : 1.0\n",
      "Training Accuracy for iterations 75 and learning rate 1.5 : 0.94\n",
      "Training Accuracy for iterations 75 and learning rate 2 : 0.94\n",
      "Training Accuracy for iterations 100 and learning rate 0.1 : 0.9933333333333333\n",
      "Training Accuracy for iterations 100 and learning rate 0.5 : 1.0\n",
      "Training Accuracy for iterations 100 and learning rate 1 : 1.0\n",
      "Training Accuracy for iterations 100 and learning rate 1.5 : 0.12333333333333334\n",
      "Training Accuracy for iterations 100 and learning rate 2 : 0.11\n"
     ]
    }
   ],
   "source": [
    "#Loop for different iterations and learning rate\n",
    "\n",
    "highest_accuracy = 0\n",
    "best_iter = 0\n",
    "best_lr = 0\n",
    "\n",
    "for iteration in (5,25,50,75,100):\n",
    "    for lr in (0.1,0.5,1,1.5,2):\n",
    "        \n",
    "        #calling training method\n",
    "        model, alpha = train_adaboost_custom(X_train, Y_train, iteration, lr)\n",
    "\n",
    "        #Prediction of output from custom adaboost\n",
    "        rows, columns = X_train.shape\n",
    "        y = np.zeros(rows)\n",
    "\n",
    "        for (m, a) in zip(model, alpha):\n",
    "            y = y + a * m.predict(X_train)\n",
    "        y_pred_train = np.sign(y)\n",
    "\n",
    "        #check accuracy on training set\n",
    "        accuracy_training = np.sum(Y_train == y_pred_train) / len(Y_train)\n",
    "\n",
    "        print (\"Training Accuracy for iterations\", iteration, \"and learning rate\", lr, \":\", accuracy_training)\n",
    "\n",
    "        if accuracy_training >= highest_accuracy:\n",
    "            highest_accuracy = accuracy_training\n",
    "            best_iter = iteration\n",
    "            best_lr = lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest training accuracy 1.0 achieved for 100 iterations and 1 learning rate\n"
     ]
    }
   ],
   "source": [
    "print(\"Highest training accuracy\", highest_accuracy, \"achieved for\", best_iter, \"iterations and\", best_lr, \"learning rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy for iterations 5 and learning rate 0.1 : 0.9328358208955224\n",
      "Testing Accuracy for iterations 5 and learning rate 0.5 : 0.9552238805970149\n",
      "Testing Accuracy for iterations 5 and learning rate 1 : 0.917910447761194\n",
      "Testing Accuracy for iterations 5 and learning rate 1.5 : 0.917910447761194\n",
      "Testing Accuracy for iterations 5 and learning rate 2 : 0.917910447761194\n",
      "Testing Accuracy for iterations 25 and learning rate 0.1 : 0.9477611940298507\n",
      "Testing Accuracy for iterations 25 and learning rate 0.5 : 0.9402985074626866\n",
      "Testing Accuracy for iterations 25 and learning rate 1 : 0.9029850746268657\n",
      "Testing Accuracy for iterations 25 and learning rate 1.5 : 0.9104477611940298\n",
      "Testing Accuracy for iterations 25 and learning rate 2 : 0.9104477611940298\n",
      "Testing Accuracy for iterations 50 and learning rate 0.1 : 0.9626865671641791\n",
      "Testing Accuracy for iterations 50 and learning rate 0.5 : 0.9552238805970149\n",
      "Testing Accuracy for iterations 50 and learning rate 1 : 0.9365671641791045\n",
      "Testing Accuracy for iterations 50 and learning rate 1.5 : 0.08582089552238806\n",
      "Testing Accuracy for iterations 50 and learning rate 2 : 0.09701492537313433\n",
      "Testing Accuracy for iterations 75 and learning rate 0.1 : 0.9552238805970149\n",
      "Testing Accuracy for iterations 75 and learning rate 0.5 : 0.9626865671641791\n",
      "Testing Accuracy for iterations 75 and learning rate 1 : 0.914179104477612\n",
      "Testing Accuracy for iterations 75 and learning rate 1.5 : 0.9104477611940298\n",
      "Testing Accuracy for iterations 75 and learning rate 2 : 0.9104477611940298\n",
      "Testing Accuracy for iterations 100 and learning rate 0.1 : 0.9589552238805971\n",
      "Testing Accuracy for iterations 100 and learning rate 0.5 : 0.9664179104477612\n",
      "Testing Accuracy for iterations 100 and learning rate 1 : 0.9402985074626866\n",
      "Testing Accuracy for iterations 100 and learning rate 1.5 : 0.08582089552238806\n",
      "Testing Accuracy for iterations 100 and learning rate 2 : 0.09701492537313433\n"
     ]
    }
   ],
   "source": [
    "highest_accuracy = 0\n",
    "best_iter = 0\n",
    "best_lr = 0\n",
    "\n",
    "for i in (5,25,50,75,100):\n",
    "    for j in (0.1,0.5,1,1.5,2):\n",
    "        #calling training method\n",
    "        model, alpha = train_adaboost_custom(X_train,Y_train,i,j)\n",
    "        \n",
    "        #Prediction of output from custom adaboost\n",
    "        rows, columns = X_test.shape\n",
    "        y = np.zeros(rows)\n",
    "\n",
    "        for (m, a) in zip(model, alpha):\n",
    "            y = y + a * m.predict(X_test)\n",
    "        y_pred_test = np.sign(y)\n",
    "        \n",
    "        accuracy_testing = np.sum(y_test == y_pred_test) / len(y_test)\n",
    "        \n",
    "        if accuracy_testing > highest_accuracy:\n",
    "            highest_accuracy = accuracy_testing\n",
    "            best_iter = i\n",
    "            best_lr = j\n",
    "           \n",
    "        print (\"Testing Accuracy for iterations\", i, \"and learning rate\", j, \":\", accuracy_testing)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest testing accuracy 0.9664179104477612 achieved for 100 iterations and 0.5 learning rate\n"
     ]
    }
   ],
   "source": [
    "print(\"Highest testing accuracy\", highest_accuracy, \"achieved for\", best_iter, \"iterations and\", best_lr, \"learning rate\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  5 learning_rate:  0.1 Accuracy: 0.9216417910447762\n",
      "iteration:  5 learning_rate:  0.5 Accuracy: 0.9477611940298507\n",
      "iteration:  5 learning_rate:  1 Accuracy: 0.9328358208955224\n",
      "iteration:  5 learning_rate:  1.5 Accuracy: 0.9253731343283582\n",
      "iteration:  5 learning_rate:  2 Accuracy: 0.917910447761194\n",
      "iteration:  25 learning_rate:  0.1 Accuracy: 0.9365671641791045\n",
      "iteration:  25 learning_rate:  0.5 Accuracy: 0.9328358208955224\n",
      "iteration:  25 learning_rate:  1 Accuracy: 0.9701492537313433\n",
      "iteration:  25 learning_rate:  1.5 Accuracy: 0.9626865671641791\n",
      "iteration:  25 learning_rate:  2 Accuracy: 0.9104477611940298\n",
      "iteration:  50 learning_rate:  0.1 Accuracy: 0.9626865671641791\n",
      "iteration:  50 learning_rate:  0.5 Accuracy: 0.9589552238805971\n",
      "iteration:  50 learning_rate:  1 Accuracy: 0.9701492537313433\n",
      "iteration:  50 learning_rate:  1.5 Accuracy: 0.9514925373134329\n",
      "iteration:  50 learning_rate:  2 Accuracy: 0.4962686567164179\n",
      "iteration:  75 learning_rate:  0.1 Accuracy: 0.9589552238805971\n",
      "iteration:  75 learning_rate:  0.5 Accuracy: 0.9477611940298507\n",
      "iteration:  75 learning_rate:  1 Accuracy: 0.9701492537313433\n",
      "iteration:  75 learning_rate:  1.5 Accuracy: 0.9664179104477612\n",
      "iteration:  75 learning_rate:  2 Accuracy: 0.8395522388059702\n",
      "iteration:  100 learning_rate:  0.1 Accuracy: 0.9626865671641791\n",
      "iteration:  100 learning_rate:  0.5 Accuracy: 0.9626865671641791\n",
      "iteration:  100 learning_rate:  1 Accuracy: 0.9664179104477612\n",
      "iteration:  100 learning_rate:  1.5 Accuracy: 0.9776119402985075\n",
      "iteration:  100 learning_rate:  2 Accuracy: 0.48507462686567165\n"
     ]
    }
   ],
   "source": [
    "highest_accuracy_sklearn = 0\n",
    "best_iter_sklearn = 0\n",
    "best_lr_sklearn = 0\n",
    "\n",
    "for iteration in (5,25,50,75,100):\n",
    "    for lr in (0.1,0.5,1,1.5,2):\n",
    "        adaboost = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators = iteration, learning_rate = lr, random_state=0)\n",
    "        adaboost = adaboost.fit(X_train, Y_train)\n",
    "        \n",
    "        y_val_adaboost = adaboost.predict(X_test)\n",
    "        \n",
    "        accuracy_sklearn_adaboost = np.sum(y_test == y_val_adaboost) / len(y_test)\n",
    "        \n",
    "        print (\"iteration: \",iteration, \"learning_rate: \", lr,  \"Accuracy:\", accuracy_sklearn_adaboost)\n",
    "        \n",
    "        if accuracy_sklearn_adaboost >= highest_accuracy_sklearn:\n",
    "            highest_accuracy_sklearn = accuracy_sklearn_adaboost\n",
    "            best_iter_sklearn = iteration\n",
    "            best_lr_sklearn = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest sklearn accuracy 0.9776119402985075  achieved for 100 iterations and 1.5 learning rate\n"
     ]
    }
   ],
   "source": [
    "print(\"Highest sklearn accuracy\", highest_accuracy_sklearn, \" achieved for\", best_iter_sklearn, \"iterations and\", best_lr_sklearn, \"learning rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 100 learning_rate: 1.5\n",
      "depth: 2 Accuracy: 0.9701492537313433\n",
      "depth: 4 Accuracy: 0.9776119402985075\n",
      "depth: 6 Accuracy: 0.8805970149253731\n",
      "depth: 8 Accuracy: 0.9067164179104478\n",
      "depth: 10 Accuracy: 0.9067164179104478\n"
     ]
    }
   ],
   "source": [
    "#sklearn adaboost with best hyperparameters and greater depth trees\n",
    "print (\"iteration:\",best_iter_sklearn, \"learning_rate:\", best_lr_sklearn)\n",
    "for k in (2,4,6,8,10):\n",
    "    aboost_deep = AdaBoostClassifier(DecisionTreeClassifier(max_depth=k), n_estimators = best_iter_sklearn, learning_rate = best_lr_sklearn, random_state=0)\n",
    "    aboost_deep = aboost_deep.fit(X_train, Y_train)\n",
    "    \n",
    "    y_val_aboost_trees = aboost_deep.predict(X_test)\n",
    "    \n",
    "    accuracy_sklearn_adaboost_trees = np.sum(y_test == y_val_aboost_trees) / len(y_test)\n",
    "    \n",
    "    print (\"depth:\", k,  \"Accuracy:\", accuracy_sklearn_adaboost_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier)\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "#metrics for accuracy calculation\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "gb = GradientBoostingClassifier()\n",
    "dt=DecisionTreeClassifier()\n",
    "svm = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_split = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adaboost classifier object with different base estimators\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "base estimators = DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for DecisionTreeClassifier as estimator: 95.8955223880597\n"
     ]
    }
   ],
   "source": [
    "boost = AdaBoostClassifier( base_estimator = DecisionTreeClassifier(max_depth = 1, max_leaf_nodes=2), \n",
    "                        algorithm = 'SAMME',n_estimators=best_iter_sklearn,learning_rate=best_lr_sklearn)\n",
    "boost.fit(X_train, Y_train)  \n",
    "\n",
    "ypred = boost.predict(X_test)\n",
    "\n",
    "print(\"Accuracy for DecisionTreeClassifier as estimator:\",metrics.accuracy_score(y_test, ypred) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "base estimators = RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for RandomForestClassifier as estimator : 95.1492537313433\n"
     ]
    }
   ],
   "source": [
    "boost = AdaBoostClassifier( base_estimator = RandomForestClassifier(n_estimators=best_iter_sklearn), \n",
    "                        algorithm = 'SAMME',learning_rate=best_lr_sklearn)\n",
    "boost.fit(X_train, Y_train)  \n",
    "\n",
    "ypred = boost.predict(X_test)\n",
    "\n",
    "print(\"Accuracy for RandomForestClassifier as estimator :\",metrics.accuracy_score(y_test, ypred) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "base estimators = SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for SVC as estimator: 92.53731343283582\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(probability=True, kernel='linear')\n",
    "\n",
    "abc = AdaBoostClassifier(base_estimator=svc, n_estimators=best_iter_sklearn, learning_rate=best_lr_sklearn)\n",
    "\n",
    "model = abc.fit(X_train, Y_train)\n",
    "\n",
    "ypred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy for SVC as estimator:\",metrics.accuracy_score(y_test, ypred) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation using SVM with different kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy 94.88888888888889\n",
      "Testing accuracy 95.06172839506173\n"
     ]
    }
   ],
   "source": [
    "linear_svm = SVC(kernel='linear')\n",
    "\n",
    "score = cross_val_score(estimator=linear_svm, X=X_train, y=Y_train, cv=cv_split)\n",
    "print(\"Training accuracy\", np.mean(score)*100)\n",
    "\n",
    "score_test = cross_val_score(estimator=linear_svm, X=X_test, y=y_test, cv=cv_split)\n",
    "print(\"Testing accuracy\", np.mean(score_test)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 87.33333333333334\n",
      "Testing accuracy: 94.07407407407406\n"
     ]
    }
   ],
   "source": [
    "rbf_svm = SVC(kernel='rbf')\n",
    "\n",
    "score = cross_val_score(estimator=rbf_svm, X=X_train, y=Y_train, cv=cv_split)\n",
    "print(\"Training accuracy:\", np.mean(score)*100)\n",
    "\n",
    "score_test = cross_val_score(estimator=rbf_svm, X=X_test, y=y_test, cv=cv_split)\n",
    "print(\"Testing accuracy:\", np.mean(score_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 44.00000000000001\n",
      "Testing accuracy: 77.03703703703704\n"
     ]
    }
   ],
   "source": [
    "sig_svm = SVC(kernel='sigmoid')\n",
    "\n",
    "score = cross_val_score(estimator=sig_svm, X=X_train, y=Y_train, cv=cv_split)\n",
    "print(\"Training accuracy:\", np.mean(score)*100)\n",
    "\n",
    "score_test = cross_val_score(estimator=sig_svm, X=X_test, y=y_test, cv=cv_split)\n",
    "print(\"Testing accuracy:\", np.mean(score_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation using Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 94.66666666666667\n",
      "Testing accuracy: 95.80246913580247\n"
     ]
    }
   ],
   "source": [
    "training_score = cross_val_score(estimator=rf, X=X_train, y=Y_train, cv=cv_split)\n",
    "print(\"Training accuracy:\", np.mean(training_score)*100)\n",
    "\n",
    "testing_score = cross_val_score(estimator=rf, X=X_test, y=y_test, cv=cv_split)\n",
    "print(\"Testing accuracy:\", np.mean(testing_score)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation using Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 92.00000000000001\n",
      "Testing accuracy: 93.82716049382715\n"
     ]
    }
   ],
   "source": [
    "training_score = cross_val_score(estimator=dt, X=X_train, y=Y_train, cv=cv_split)\n",
    "print(\"Training accuracy:\",np.mean(training_score)*100)\n",
    "\n",
    "testing_score = cross_val_score(estimator=dt, X=X_test, y=y_test, cv=cv_split)\n",
    "print(\"Testing accuracy:\", np.mean(testing_score)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
